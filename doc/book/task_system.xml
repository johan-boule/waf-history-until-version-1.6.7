<?xml version='1.0'?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN"
"http://www.oasis-open.org/docbook/xml/4.3/docbookx.dtd"
>
<chapter>
	<title>The Task system</title>
	<section>
		<title>Task creation and execution</title>
		<para>
			When Waf tasks are created, they are not executed immediately, for example it is not necessary to rebuild an application if the source files have not changed. Some tasks may also depend on other tasks which may not be created yet. For this reasons Waf delays the execution of tasks to the point when all build functions have been executed.
		</para>
		<para>
			Creating all tasks by hand is a tedious process that the task generators (<xref  linkend="task_gen"/>) may automate. Before starting the build, Waf asks each task generator to produce the corresponding tasks. If Waf is launched from a subfolder inside the source directory, it will try to avoid the creation of the tasks that are not relevant for that particular subfolder (optimization).
		</para>
		<para>
		 	Once the tasks are created, Waf will review each of them one by one to decide whether to execute them or not. A summary can be found on the following diagram:
			<graphic format="png" fileref="task_execution.png" align="center"/>
		</para>
	</section>

	<section>
		<title>Task execution</title>
		<para>
			Executing a task consists in calling the method <emphasis>run</emphasis> on that task, and setting the task execution state.
			The following diagram is a summary of the process:
			<graphic format="png" fileref="task_run.png" align="center"/>
			The method <emphasis>post_run</emphasis> can be used to check if the files have been produced, it must throw an OSError if the task has not completed properly.
		</para>
	</section>

	<section>
		<title>Task execution in parallel</title>
		<para>
			Tasks may be executed in parallel to take advantage of the hardware (multi-core) or the environment (distributed builds). By default Waf does not execute immediately the tasks that are ready. Instead, tasks are added to a queue which is consumed by threads. Waf detects the number of installed processsors. For uni-processor only one task is executed at a time, for dual-processors two tasks are executed at a time, and so on. To disable task parallelization, use the option <emphasis>-j1</emphasis>. To enhance parallelization, use the option <emphasis>-j</emphasis> with the amount of consumers:
			<programlisting language="sh">
$ waf -j3
			</programlisting>
		</para>
		<para>
			By default, Waf does not allow consumer threads to access the tasks directly:
			<itemizedlist>
				<listitem>There is little need for parallelizing the computation of the next task to execute, choosing the next task is fast enough</listitem>
				<listitem>The thread issues are limited to a very small section of the code</listitem>
				<listitem>The producer-consumer scheme prevents <emphasis>busy waiting</emphasis> for the next task</listitem>
				<listitem>A simple global error handler can be used for processing the errors and to decide to stop the build</listitem>
			</itemizedlist>
			The following illustrates the relationship producer-consumer performed for the builds:
			<graphic format="png" fileref="parallel.png" align="center"/>
		</para>
	</section>

	<section>
		<title>Task ordering</title>
			<para>
				Running tasks in parallel is a simple problem, but in practice it is more complicated:
				<itemizedlist>
					<listitem>Dependencies can be discovered during the build (dynamic task creation)</listitem>
					<listitem>New ordering constraints can be discovered after files are compiled</listitem>
					<listitem>The amount of tasks and ordering constraints (graph size) can be huge and performance may be a problem</listitem>
				</itemizedlist>

				To make the problem more simple, it is divided by the different concerns, and the orderring constraints can be given on three different levels:
				<orderedlist>
					<listitem>groups of tasks may run only after another group of tasks has finished to run, this represents a strict sequential order between groups of tasks, for example a compiler is produced and used to compile the tasks in the next group</listitem>
					<listitem>task types to indicate the instance will run after other task type instances, for example linking object files may only occur after compiling the source files</listitem>
					<listitem>specific constraints for task instances that can only run after a few other task instances</listitem>
				</orderedlist>
			</para>
			<sect2>
				<title>Task groups</title>
				<para>
					The following is used to declare groups of tasks to run one after the other:
					<programlisting language="python">
def build(bld):
	# create a few tasks
	bld.add_group()
	# create new tasks
					</programlisting>
					The effect of task groups when running tasks in parallel is illustrated by the following diagram. Three groups of tasks have been added, and the execution of the next group only starts when the execution of the tasks in the previous group is complete.
					<graphic format="png" fileref="output-ADDGROUP.png" align="center"/>
				</para>
			</sect2>

			<sect2>
				<title>Precedence constraints</title>
				<para>
					The attributes <emphasis>before</emphasis> and <emphasis>after</emphasis> are used to declare ordering constraints between tasks:
					<programlisting language="python">
import Task
class task_test_a(Task.TaskBase):
	before = 'task_test_b'
class task_test_b(Task.TaskBase):
	after = 'task_test_a'
					</programlisting>
					Another way to declare precedence constraints is to declare a file extension production, for example:
					<programlisting language="python">
import Task
class task_test_a(Task.TaskBase):
	ext_in = '.c'
class task_test_b(Task.TaskBase):
	ext_out = '.c'
					</programlisting>
					The extensions have to match to add a valid precedence constraint, but they are only annotations, they do not mean the tasks actually have to produce files of that type.
				</para>
			</sect2>

			<sect2>
				<title>Precedence constraints on task instances</title>
				<para>
					The method <emphasis>set_run_after</emphasis> is used to declare ordering constraints between tasks:
					<programlisting language="python">
task1.set_run_after(task2)
					</programlisting>
					unlike the previous constraints, it is used on the instances of class <emphasis>Task</emphasis> which is a subclass of class <emphasis>TaskBase</emphasis>
				</para>
			</sect2>

	</section>

	<section>
		<title>Executing tasks only when something changes</title>
		<para>The direct instances of TaskBase are quite limited and do not track the changes to the source files. The class <emphasis>Task</emphasis> provides the necessary features for the most common builds in which source files are used to produce target files. The idea is to create a unique signature for tasks, and to represent the dependencies on files or other tasks by including them in the signature. A hashing function is used for computing the signature, by default it is md5.
		</para>
		<para>
			The following diagram illustrates the task processing including the signature, it is only valid for Task instance (not TaskBase instances):
			<graphic format="png" fileref="task_signature.png" align="center"/>
		</para>
		<para>
			The signature computation uses the following data:
			<orderedlist>
				<listitem>explicit dependencies: input files and dependencies set explicitly using task.deps_man or bld.depends_on</listitem>
				<listitem>implicit dependencies: dependencies searched by the task itself (like source files included from other source files).</listitem>
				<listitem>parameters: compilation flags and command-line parameters.</listitem>
			</orderedlist>
			Here is an example illustrating the different kinds of dependencies:
			<programlisting language="python">
import Task
class task_demo(Task.Task):
	vars = ['CXXFLAGS', 'LINKFLAGS'] <co id="vars-co" linkends="vars"/>
	def scan(self): <co id="scan-co" linkends="scan"/>
		return [[self.inputs[0].parent.find_resource('.svn/entries')], []]

task = task_demo()
task.inputs = [bld.path.find_resource('test.cxx')] <co id="expl-co" linkends="expl"/>
task.deps_man = [bld.path.find_resource('wscript')] <co id="expl2-co" linkends="expl2"/>

bld.add_manual_dependency('main.c', 'an arbitrary string value') <co id="expl3-co" linkends="expl3"/>
bld.add_manual_dependency(
		bld.path.find_or_declare('test_c_program'),
		bld.path.find_resource('bbb')) <co id="expl4-co" linkends="expl4"/>
			</programlisting>
			<calloutlist>
				<callout arearefs="vars-co" id="vars">
					<para>Environment variable dependencies (compilation flags)</para>
				</callout>
				<callout arearefs="scan-co" id="scan">
					<para>Implicit dependencies: a method returns a list containing the list of additional nodes to take into account, and the list of the files that could not be found (cache)</para>
				</callout>
				<callout arearefs="expl-co" id="expl">
					<para>Explicit dependencies as input files (nodes)</para>
				</callout>
				<callout arearefs="expl2-co" id="expl2">
					<para>Explicit dependencies as manual dependencies</para>
				</callout>
				<callout arearefs="expl3-co" id="expl3">
					<para>Manual dependencies on source files, the second parameter can be a string, a node object or a function returning a string</para>
				</callout>
				<callout arearefs="expl4-co" id="expl4">
					<para>Manual dependencies with nodes, the first node represents a target (which may or may not exist in the build), and the second parameter represents a file in the source directory.</para>
				</callout>
			</calloutlist>

		</para>
	</section>

</chapter>

